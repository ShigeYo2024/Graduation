import streamlit as st
import openai
import json
import os
import pandas as pd
import io
import random  # â† ã“ã‚Œã‚’è¿½åŠ 

# Streamlitã®Secretsã‹ã‚‰OpenAI API keyã‚’å–å¾—
openai.api_key = st.secrets["OpenAIAPI"]["openai_api_key"]


# DXæ¨é€²ã‚¹ãƒ†ãƒ¼ã‚¸ã®é¸æŠè‚¢
dx_stages = ["å°å…¥å‰", "å°å…¥åˆæœŸ", "å°å…¥æ¨é€²ä¸­", "å®šç€æœŸ"]

# ãƒšãƒ«ã‚½ãƒŠã®èª­ã¿è¾¼ã¿
def load_personas(file_path):
    with open(file_path, "r", encoding="utf-8") as file:
        personas_data = json.load(file)

        # "DX Stages" ãŒ "RANDOM" ã®å ´åˆã€ãƒ©ãƒ³ãƒ€ãƒ ãªã‚¹ãƒ†ãƒ¼ã‚¸ã‚’ä»£å…¥
        for persona in personas_data["personas"]:
            if persona["DX Stages"] == "RANDOM":
                persona["DX Stages"] = random.choice(dx_stages)

    return personas_data["personas"]  # ä¿®æ­£: withãƒ–ãƒ­ãƒƒã‚¯ã®å¤–ã§return

# ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼è³ªå•ã®èª­ã¿è¾¼ã¿
def load_questions(file_path):
    with open(file_path, "r") as file:
        questions = json.load(file)
    return questions["questions"]

# persona_questions.jsonã®èª­ã¿è¾¼ã¿
def load_persona_questions(file_path):
    with open(file_path, "r") as file:
        persona_questions = json.load(file)
    return persona_questions

# ãƒšãƒ«ã‚½ãƒŠã¨ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼è³ªå•ãƒ•ã‚¡ã‚¤ãƒ«ã¨DXèª²é¡Œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆpersona_questionsï¼‰ã‚’èª­ã¿è¾¼ã‚€
personas = load_personas("persona.json")
interview_questions = load_questions("interview_questions.json")
persona_questions = load_persona_questions("persona_questions.json")

# ãƒšãƒ«ã‚½ãƒŠã®é¸æŠ
persona_names = [f"{p['id']}. {p['name']} ({p['job']})" for p in personas]
selected_persona = st.selectbox("ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ãƒšãƒ«ã‚½ãƒŠã‚’é¸ã‚“ã§ãã ã•ã„:", persona_names)

# é¸æŠã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠã®æƒ…å ±ã‚’å–å¾—
persona_id = int(selected_persona.split(".")[0]) - 1
persona = personas[persona_id]

# ãƒšãƒ«ã‚½ãƒŠæƒ…å ±ã®è¡¨ç¤º
st.title(f"DXæ¨é€²ãƒªãƒ¼ãƒ€ãƒ¼: {persona['name']}ã•ã‚“ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼")
st.write(f"**è·æ¥­:** {persona['job']}")
st.write(f"**ç›®æ¨™:** {persona['goals']}")
st.write(f"**èª²é¡Œ:** {persona['challenges']}")
st.write(f"**DXæ¨é€²ã‚¹ãƒ†ãƒ¼ã‚¸:** {persona['DX Stages']}")

# **è³ªå•ã‚«ãƒ†ã‚´ãƒªï¼ˆDXã‚¹ãƒ†ãƒ¼ã‚¸ã‚’è€ƒæ…®ï¼‰**
question_categories = {
    "çµ„ç¹”èª²é¡Œ": f"{persona['DX Stages']}ã«ãŠã‘ã‚‹çµ„ç¹”ã®å£ã‚„ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã®èª²é¡Œã«ã¤ã„ã¦è³ªå•ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚",
    "æŠ€è¡“èª²é¡Œ": f"{persona['DX Stages']}ã«ãŠã‘ã‚‹ãƒ‡ã‚¸ã‚¿ãƒ«æŠ€è¡“å°å…¥ã«é–¢ã™ã‚‹è³ªå•ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚",
    "å°å…¥å¾Œã®è©•ä¾¡": f"{persona['DX Stages']}ã«ãŠã‘ã‚‹DXå°å…¥å¾Œã®æˆæœæ¸¬å®šã€PDCAã®æœ€é©åŒ–ã«é–¢ã™ã‚‹è³ªå•ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚",
    "KPIè¨­å®š": f"{persona['DX Stages']}ã«ãŠã‘ã‚‹DXãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®KPIè¨­å®šã€ãƒ‡ãƒ¼ã‚¿åˆ†æã®æ´»ç”¨ã«é–¢ã™ã‚‹è³ªå•ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚",
    "ç¾å ´å¯¾å¿œ": f"{persona['DX Stages']}ã«ãŠã‘ã‚‹ç¾å ´å¾“æ¥­å“¡ã®æ•™è‚²ã€æ¥­å‹™å¤‰é©ã«é–¢ã™ã‚‹è³ªå•ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚",
}

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": f"ã‚ãªãŸã¯DXæ¨é€²ã‚³ãƒ¼ãƒã§ã™ã€‚{persona['job']}ã®{persona['name']}ã•ã‚“ã®èª²é¡Œè§£æ±ºã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚"}
    ]

if "feedbacks" not in st.session_state:
    st.session_state["feedbacks"] = []

# **è³ªå•ç”Ÿæˆ**
def generate_questions(persona):
    questions_by_category = {}

    for category, instruction in question_categories.items():
        prompt = f"""
        ã‚ãªãŸã¯{persona['job']}ã®{persona['name']}ã§ã™ã€‚
        ä»¥ä¸‹ã®ç›®æ¨™ã¨èª²é¡Œã€DXæ¨é€²ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’è¸ã¾ãˆã€{category}ã«é–¢ã™ã‚‹è³ªå•ã‚’1ã¤è€ƒãˆã¦ãã ã•ã„ã€‚

        **ç›®æ¨™:** {persona['goals']}
        **èª²é¡Œ:** {persona['challenges']}
        **DXæ¨é€²ã‚¹ãƒ†ãƒ¼ã‚¸:** {persona['DX Stages']}

        **è³ªå•ã®æŒ‡ç¤º:** {instruction}

        **è³ªå•:** 
        """

        try:
            response = openai.ChatCompletion.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯DXæ¨é€²ã®ãƒªãƒ¼ãƒ€ãƒ¼ã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=600
            )
            questions_by_category[category] = response["choices"][0]["message"]["content"].strip().split("\n")
        except Exception as e:
            st.error(f"è³ªå•ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            questions_by_category[category] = []

    return questions_by_category

# **è³ªå•ã«å¯¾ã™ã‚‹AIã®å›ç­”ç”Ÿæˆ**
def chat_with_ai(persona, question):
    prompt = f"""
    ã‚ãªãŸã¯DXæ¨é€²ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚³ãƒ¼ãƒã§ã™ã€‚
    {persona['job']}ã®{persona['name']}ãŒä»¥ä¸‹ã®è³ªå•ã‚’ã—ã¾ã—ãŸã€‚
    
    è³ªå•:
    {question}

    ã“ã‚Œã«å¯¾ã—ã¦ã€DXæ¨é€²ã«é–¢ã™ã‚‹çŸ¥è­˜ã‚’æ´»ç”¨ã—ã€600å­—ä»¥å†…ã®å…·ä½“çš„ã§å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
    é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’3ã¤ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
    """

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯DXæ¨é€²ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚³ãƒ¼ãƒã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=600
        )
        return response["choices"][0]["message"]["content"].strip()
    except Exception as e:
        st.error(f"AIã®å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return "å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

# **è³ªå•ã¨AIã®å›ç­”ã®è¡¨ç¤º**
if st.button(f"{persona['name']}ã®è³ªå•ã‚’é–‹å§‹", key="start_questions"):
    auto_questions = generate_questions(persona)

    for category, questions in auto_questions.items():
        st.subheader(f"ğŸ“Œ {category} ã®è³ªå• ({persona['DX Stages']})")
        for question in questions:  
            # è³ªå•ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã¨ã—ã¦ä¿å­˜
            user_message = {"role": "user", "content": question}
            st.session_state["messages"].append(user_message)

            # AIã®å›ç­”ã‚’ç”Ÿæˆ
            ai_response = chat_with_ai(persona, question)

            # AIã®å›ç­”ã‚’ä¿å­˜
            ai_message = {"role": "assistant", "content": ai_response}
            st.session_state["messages"].append(ai_message)

            # **è³ªå•ã¨å›ç­”ã®è¡¨ç¤º**
            st.write(f"ğŸ™‚ **è³ªå•:** {question}")
            st.write(f"ğŸ¤– **AIã®å›ç­”:** {ai_response}")

# ãƒšãƒ«ã‚½ãƒŠã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
def generate_feedback(persona, chat_history):
    """
    ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ä½“é¨“ã«åŸºã¥ãã€ãƒšãƒ«ã‚½ãƒŠã‹ã‚‰ã®å…·ä½“çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
    """

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’æ•´å½¢
    chat_content = "\n".join([msg["content"] for msg in chat_history if msg["role"] in ["user", "assistant"]])

    # ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã®è³ªå•ãƒªã‚¹ãƒˆã‚’æ•´å½¢
    questions_formatted = "\n".join([f"{i+1}. {q}" for i, q in enumerate(interview_questions)])

    prompt = f"""
    ã‚ãªãŸã¯{persona['job']}ã®{persona['name']}ã§ã™ã€‚
    ä»¥ä¸‹ã¯ã‚ãªãŸãŒAIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã‚„ã‚Šå–ã‚Šã—ãŸå†…å®¹ã§ã™ã€‚ã“ã®çµŒé¨“ã‚’åŸºã«ã€ä»¥ä¸‹ã®3ã¤ã®è¦³ç‚¹ã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

    1. **ç‰¹ã«å½¹ç«‹ã£ãŸãƒãƒ£ãƒƒãƒˆã®ã‚„ã‚Šå–ã‚Š**  
       - ã©ã®è³ªå•ã«å¯¾ã™ã‚‹AIã®å›ç­”ãŒç‰¹ã«å½¹ç«‹ã¡ã¾ã—ãŸã‹ï¼Ÿ  
       - ãã‚Œã¯ãªãœå½¹ç«‹ã£ãŸã®ã‹ã€å…·ä½“çš„ãªç†ç”±ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚

    2. **æœŸå¾…ã¨ç•°ãªã£ã¦ã„ãŸç‚¹**  
       - ã©ã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ãŒæœŸå¾…ã¨é•ã„ã¾ã—ãŸã‹ï¼Ÿ  
       - ã©ã®éƒ¨åˆ†ãŒè¶³ã‚Šãªã‹ã£ãŸã‹ã€ã©ã®ã‚ˆã†ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ãŸã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

    3. **ä»Šå¾Œã®æ”¹å–„ç‚¹ã¨å…·ä½“çš„ãªææ¡ˆ**  
       - ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒã‚ˆã‚Šæœ‰ç›Šãªå›ç­”ã‚’ã™ã‚‹ãŸã‚ã«ã€ã©ã®ã‚ˆã†ãªæ”¹å–„ãŒå¿…è¦ã§ã™ã‹ï¼Ÿ  
       - å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªæƒ…å ±ã‚’è¿½åŠ ã™ã‚‹ã¨è‰¯ã„ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ

    **ãƒãƒ£ãƒƒãƒˆå±¥æ­´:**
    {chat_content}

    **ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã®è³ªå•ãƒªã‚¹ãƒˆ:**
    {questions_formatted}

    **ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯:**
    """

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯DXæ¨é€²ãƒªãƒ¼ãƒ€ãƒ¼ã¨ã—ã¦ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’åˆ©ç”¨ã—è©•ä¾¡ã™ã‚‹ç«‹å ´ã®äººã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.6  # å…·ä½“æ€§ã‚’æŒãŸã›ã‚‹ãŸã‚ã«å°‘ã—ä½ã‚ã«èª¿æ•´
        )
        feedback = response["choices"][0]["message"]["content"].strip()
        st.session_state["feedbacks"].append(feedback)
        return feedback
    except openai.error.OpenAIError as e:
        st.error(f"OpenAI APIã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆãƒœã‚¿ãƒ³
if st.button(f"{persona['name']}ã•ã‚“ã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–å¾—"):
    feedback = generate_feedback(persona, st.session_state["messages"])
    st.write(f"ğŸ“œ {persona['name']}ã•ã‚“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯:")
    st.write(feedback)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
if st.session_state["messages"]:
    for message in reversed(st.session_state["messages"][1:]):
        speaker = "ğŸ™‚" if message["role"] == "user" else "ğŸ¤–"
        st.write(f"{speaker}: {message['content']}")

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã®è¡¨ç¤º
if st.session_state["feedbacks"]:
    st.write("ğŸ“„ ã“ã‚Œã¾ã§ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´:")
    for feedback in reversed(st.session_state["feedbacks"]):
        st.write(feedback)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’Excelã«ä¿å­˜
def save_chat_history_to_excel(persona_id, messages):
    if messages:
        df = pd.DataFrame(messages)
        filename = f"chat_history_persona_{persona_id}.xlsx"
        df.to_excel(filename, index=False, encoding="utf-8", engine="openpyxl")
        return filename
    return None

# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã‚’Excelã«ä¿å­˜
def save_feedback_history_to_excel(persona_id, feedbacks):
    if feedbacks:
        df = pd.DataFrame(feedbacks, columns=["ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"])
        filename = f"feedback_history_persona_{persona_id}.xlsx"
        df.to_excel(filename, index=False, encoding="utf-8", engine="openpyxl")
        return filename
    return None

# Excelãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
def download_excel_file(file_path, label):
    if os.path.exists(file_path):
        with open(file_path, "rb") as file:
            st.download_button(label, data=file, file_name=file_path, mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        st.warning(f"{file_path} ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚å…ˆã«Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¦ãã ã•ã„ã€‚")

# Excelä¿å­˜ãƒœã‚¿ãƒ³
if st.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’Excelã§ä¿å­˜"):
    chat_file = save_chat_history_to_excel(persona["id"], st.session_state.get("messages", []))
    if chat_file:
        st.success(f"{persona['name']}ã•ã‚“ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’Excelã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    else:
        st.warning("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

if st.button("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã‚’Excelã§ä¿å­˜"):
    feedback_file = save_feedback_history_to_excel(persona["id"], st.session_state.get("feedbacks", []))
    if feedback_file:
        st.success(f"{persona['name']}ã•ã‚“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã‚’Excelã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    else:
        st.warning("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
download_excel_file(f"chat_history_persona_{persona['id']}.xlsx", "ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
download_excel_file(f"feedback_history_persona_{persona['id']}.xlsx", "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

