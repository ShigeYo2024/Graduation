import streamlit as st
import openai
import json
from textblob import TextBlob
import matplotlib.pyplot as plt
from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex, StorageContext, load_index_from_storage

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
openai.api_key = st.secrets.OpenAIAPI.openai_api_key

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æº–å‚™
try:
    storage_context = StorageContext.from_defaults(persist_dir="./index")
    index = load_index_from_storage(storage_context)
except:
    documents = SimpleDirectoryReader(input_dir="./documents").load_data()
    index = GPTVectorStoreIndex.from_documents(documents)
    index.storage_context.persist(persist_dir="./index")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "system", "content": """ã‚ãªãŸã¯ã‚°ãƒ¬ã‚´ãƒªãƒ¼ãƒ»ãƒ™ã‚¤ãƒˆã‚½ãƒ³ã®æ•™è‚²ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ãŸæ•™è‚²ã‚³ãƒ¼ãƒã§ã™ã€‚ä»¥ä¸‹ã‚’è¡Œã„ã¾ã™ï¼š\n1. æ„Ÿæƒ…çŠ¶æ…‹ã‚’åˆ†æã€‚\n2. å­¦ç¿’æ®µéšã«å¿œã˜ãŸå¯¾è©±ã‚’æä¾›ã€‚\n3. å†…çœã‚’ä¿ƒé€²ã€‚"""}
    ]

# æ„Ÿæƒ…åˆ†æé–¢æ•°
def analyze_emotion(text):
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    if polarity > 0.5:
        return "ãƒã‚¸ãƒ†ã‚£ãƒ–"
    elif polarity < -0.5:
        return "ãƒã‚¬ãƒ†ã‚£ãƒ–"
    else:
        return "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"

# RAGã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆ
def generate_rag_response(user_input):
    query_engine = index.as_query_engine()
    response = query_engine.query(user_input)
    return response.response

# OpenAI APIã§è¿½åŠ è³ªå•ã‚’ç”Ÿæˆ
def generate_openai_questions(rag_response):
    prompt = f"ä»¥ä¸‹ã®å†…å®¹ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã•ã‚‰ã«æ·±ãè€ƒãˆã‚‹ã¹ãè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\n{rag_response}\n\nä¸è¶³ã—ã¦ã„ã‚‹è¦³ç‚¹ã‚’è€ƒæ…®ã—ãŸè³ªå•ã‚’3ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚"
    response = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[{"role": "system", "content": "ã‚ãªãŸã¯å„ªç§€ãªAIã‚³ãƒ¼ãƒã§ã™ã€‚"},
                  {"role": "user", "content": prompt}]
    )
    return response["choices"][0]["message"]["content"]

# å­¦ç¿’æ®µéšã”ã¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
def generate_stage_message(stage, user_input):
    if stage == "zero_learning":
        return f"ã‚ãªãŸã®åŸºæœ¬çŸ¥è­˜ã‚’ç¢ºèªã—ã¾ã™: {user_input}"
    elif stage == "first_learning":
        return f"æ–°ã—ã„æ–¹æ³•ã«ã¤ã„ã¦è€ƒãˆã¦ã¿ã¾ã—ã‚‡ã†: {user_input}"
    elif stage == "second_learning":
        return f"ã‚ãªãŸã®è€ƒãˆæ–¹ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™: {user_input}"
    elif stage == "third_learning":
        return f"ã‚ˆã‚Šå¤§ããªè¦–ç‚¹ã§ã‚ãªãŸã®ä¸–ç•Œè¦³ã‚’å†æ§‹ç¯‰ã—ã¦ã¿ã¾ã—ã‚‡ã†: {user_input}"

# æ¬¡ã«è€ƒãˆã‚‹ã¹ãè³ªå•ã®ææ¡ˆ
def propose_next_questions():
    return [
        "ã“ã®è¦–ç‚¹ã‚’ã•ã‚‰ã«åºƒã’ã‚‹ã«ã¯ã©ã‚“ãªè³ªå•ãŒæœ‰åŠ¹ã§ã™ã‹ï¼Ÿ",
        "æ¬¡ã«ã©ã®ã‚ˆã†ãªè¡Œå‹•ã‚’å–ã‚‹ã¹ãã§ã™ã‹ï¼Ÿ",
        "ä»–è€…ã®æ„è¦‹ã‚’å–ã‚Šå…¥ã‚Œã‚‹ãªã‚‰ã©ã†ã—ã¾ã™ã‹ï¼Ÿ"
    ]

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜ã™ã‚‹é–¢æ•°
def save_chat_history(messages):
    with open("chat_history.txt", "a", encoding="utf-8") as file:
        for message in messages:
            file.write(f"{message['role']}: {message['content']}\n")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
def index_chat_history():
    documents = SimpleDirectoryReader("./").load_data()
    index = GPTVectorStoreIndex.from_documents(documents)
    return index

# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å¿œç­”å‡¦ç†
def communicate():
    user_input = st.text_input("ä»Šã®èª²é¡Œã‚„è€ƒãˆãŸã„ã“ã¨ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚", key="user_input")
    if user_input:
        st.session_state["messages"].append({"role": "user", "content": user_input})

        # æ„Ÿæƒ…åˆ†æ
        emotion = analyze_emotion(user_input)
        st.session_state["messages"].append({"role": "assistant", "content": f"æ„Ÿæƒ…åˆ†æçµæœ: {emotion}"})

        # å­¦ç¿’æ®µéšã®åˆ¤å®š (ä»®ã®ãƒ­ã‚¸ãƒƒã‚¯)
        if "åŸºç¤" in user_input:
            stage = "zero_learning"
        elif "æ–¹æ³•" in user_input:
            stage = "first_learning"
        elif "ãƒ‘ã‚¿ãƒ¼ãƒ³" in user_input:
            stage = "second_learning"
        else:
            stage = "third_learning"

        # å­¦ç¿’æ®µéšã«åŸºã¥ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
        stage_message = generate_stage_message(stage, user_input)
        st.session_state["messages"].append({"role": "assistant", "content": stage_message})

        # RAGã‹ã‚‰ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆ
        rag_response = generate_rag_response(user_input)
        st.session_state["messages"].append({"role": "assistant", "content": f"RAGã«ã‚ˆã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹: {rag_response}"})

        # OpenAI APIã§ã®è£œå®Œ
        additional_questions = generate_openai_questions(rag_response)
        st.session_state["messages"].append({"role": "assistant", "content": f"ã•ã‚‰ã«è€ƒãˆã‚‹ã¹ãè³ªå•: {additional_questions}"})

        # æ¬¡ã®å€™è£œè³ªå•ã‚’ææ¡ˆ
        next_questions = propose_next_questions()
        st.session_state["messages"].append({"role": "assistant", "content": f"æ¬¡ã«è€ƒãˆã‚‹ã¹ãç‚¹: {', '.join(next_questions)}"})

# UIæ§‹ç¯‰
st.title("DX & åŒ ãƒ¡ã‚½ãƒƒãƒ‰ AIã‚³ãƒ¼ãƒ")
communicate()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ä¿å­˜ãƒœã‚¿ãƒ³
if st.button("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä¿å­˜ã™ã‚‹"):
    save_chat_history(st.session_state["messages"])
    st.success("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸï¼")

# å±¥æ­´ã®æ¤œç´¢
if st.button("éå»ã®å±¥æ­´ã‹ã‚‰æ¤œç´¢ã™ã‚‹"):
    index = index_chat_history()
    query_engine = index.as_query_engine()
    query = st.text_input("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if query:
        response = query_engine.query(query)
        st.write(f"æ¤œç´¢çµæœ: {response}")

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
if st.session_state["messages"]:
    for message in reversed(st.session_state["messages"]):
        role = "ğŸ™‚" if message["role"] == "user" else "ğŸ¤–"
        st.write(f"{role}: {message['content']}")
